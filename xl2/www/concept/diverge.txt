<!--Evaluating Languages by Concept Programming Standards-->

In addition to {concept "language_limits" "built-in limits"}, which
are an obstacle to comfortably {concept "representations" "representing"} 
a {concept "anything" "wide variety of concepts"}, many languages
exhibit characteristics which do not rank well by concept
programming {@metrics}. Let's consider four simple examples, by no
means exhaustive:

<H4>Output parameters in C</H4>

Unlike several other languages (for instance {@Ada}), {@C} doesn't feature
output parameters. Rather, based on the observation that many
compilers of the old times used by-reference argument for output
parameters, C requested programmers to make the reference explicit
(a pointer) whenever they want an output parameter.

For instance, C programmers cannot write the following:
{pre}/* Illegal C */
errorcode_t GetWindowBounds(in window_t win, out rect_t rect);{erp}

Instead, they need to write something like:
{pre}errorcode_t GetWindowBounds(window_t win, rect_t *rect);{erp}
where the {tt "rect_t *"} notation (a pointer to a {tt "rect_t"})
really means <EM>{tt "rect"} is an output parameter</EM> rather
than <EM>{tt "rect"} is a pointer</EM>.

This is the archetypal example of {@semnoise}: the notation introduce
a significant semantic difference between what the programmer means
(getting data out of the function) and what he needs to write
(passing a parameter containing the address where data can be
copied). The notation also introduces a bit of {@synnoise}, since the
* notation doesn't represent anything in the {@pb}.

Why is this bad? Here is one reason: on any modern 64-bit
architecture, the {tt "rect_t"} structure might fit in one or two
64-bit words (for 16-bit or 32-bit coordinates respectively). Passing
two registers out of the function is certainly much faster than
passing one register and then performing four sub-word stores (in
the {tt "GetWindowBounds"} function) followed by four sub-word loads
(in the caller, to retrieve the data). In general, exposing pointers
to unknown addresses like this also reduces optimization
opportunities dramatically. This is a general rule: {@semnoise}
{concept "perf" "limits possible optimizations"} because the compiler
gets an incomplete or incorrect view of the desired semantics.


<H4>Parentheses in Lisp</H4>

{@Lisp} has a very small number of very powerful core constructs. Among
these is the notion of list. Practically anything in Lisp is a
list. In particular, programs are written as lists. This makes the
manipulation of programs fragments by Lisp programs not only possible, but
quite easy. This is a very powerful tool, and a necessary basis for
{concept "extension" "language extensions"}.

However, Lisp lists, while very easy to parse and store for computers,
are not the ideal representation for a number of very fundamental
concepts. Consider something as simple as the addition. In standard
Lisp, to add two and two, you do not write {tt "2 + 2"} but rather
{tt "(+ 2 2)"}, which is a Lisp list containing three elements, the +
symbol and two numbers. According to Lisp rules, this list will
evaluate as 4. This notation is called <em>prefix
{wiki "Polish_notation" "polish notation"}</em>, and is close in
principle  to the
<em>{wiki "Reverse_Polish_notation" "reverse polish notation"}</em>
 (RPN used in many HP calculators.

This notation is universal, simple to understand, and easy to
implement. But it is not the natural notation we have been taught in
school. This is an example of {@synnoise} where the syntax being used
is constrained by the tool, rather than by the choice of the
programmer. The fact that some programmers would
actually <EM>choose</EM> this notation if given a choice illustrates
how subjective the concept programming {concept "metrics"} are.


<H4>Expressions in Smalltalk</H4>

In {@Smalltalk}, you can actually write {tt "2 + 2"}, and it does indeed
computes 4. So far, so good.

Unfortunately, the familiar notation hides a particularly sneaky form
of {@semnoise}, and expressions will give the familiar result
only for the simplest scenario. This is because in Smalltalk,
everything is an object, and expressions had to bend to that rule. So
when you write {tt "2 + 2"}, what this really means is: <EM>send
  object {tt "2"} the message {tt "+"} with argument {tt "2"}</EM>.

Why does it matter? Consider an expression such as {tt "2+3*5"}. In
traditional notation, precedences are such that {tt "3*5"} is
computed first, so the result is {tt "2+15"}, or {tt "17"}. Not so in
Smalltalk, where {tt "2"} receives message {tt "+"} with argument
{tt "3"} and the resulting object, {tt "5"}, receives the message
{tt "*"} with the argument {tt "5"}. The resulting value is {tt "25"}.

Of course, one could argue that this is really a form of {@synnoise}
and that appropriate precedences could easily be restored with a
minor change in the language. But the point is that the default
precedences are not <EM>the one some people think they know</EM>, and
this causes unnecessary risks for programmers.


<H4>The 'string' types</H4>

Originally, a {wiki "String" "string"} was seen as some ideal,
variable-sized array of contiguous elements. Of particular interest
was the notion of <em>string of characters</em>, which was generally
used to represent text. For instance, in practically any language,
something like {tt "\"Hello World\""} is called a string of
characters. In practice, most early languages implemented fixed-size
arrays (as a built-in construct), but did not provide a
general-purpose string construct for arbitrary types. Yet, because of
their use to represent text, character strings were often implemented
as a special, built-in case.

Consequently, in many languages, the term {tt "string"} ended up being
understood as "string of character", and the type system sometimes
contained this denomination. {@Pascal} or {@C++} are examples of languages
where the term "string" really denotes a string of characters, in
other words what anybody but programmers would call <em>text</em>. In an
interesting twist, when C++ developers introduced what could arguably
be thought of as a real "string" type, they called it {tt "vector"},
despite the fact that it is quite different from a mathematical
vector, and reserved {tt "string"} for strings of characters.

{@xl} features a general {example "string" "variable-sized array type"},
which is consequently called {tt "string"} and not something like
vector. A particular {example "text" "instance of that type"} is
called {tt "text"} and used to represent text in the {@code}. The
{tt "text"} type is actually implemented as {tt "string of character"}.
You can, however, make use of a {tt "string of integer"} if this is
what you need, and it will behave much like a
{tt "vector&lt;int&gt;"} in C++


<H4>Conclusion</H4>

We can reasonably assert that the designers of existing programming
languages were smart and did as good a job as they could. Therefore,
the shortcomings illustrated by {@cp} are not obvious. The {@cp}
methodology brings something new to the programmers' toolbox.

None of the problems above are really serious. They only serve as an
illustration of how simple {@metrics} can be used to identify
otherwise non-obvious issues. There are many cases where the problem
is much more difficult to pinpoint without the appropriate tools, and
where its effects are much more subtle and/or more dangerous.

